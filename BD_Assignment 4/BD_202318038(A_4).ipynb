{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<font size=\"6\">Name : Digesh Patel</font><br>\n",
        "<font size=\"6\">ID : 202318038</font><br>\n",
        "<font size=\"6\">Big Data Processing</font><br>"
      ],
      "metadata": {
        "id": "nkMn0yyHuXSU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font size=\"7\">Assignment 4</font><br>**"
      ],
      "metadata": {
        "id": "jsJvQTgxwCsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=\"6\">RDD Task-1</font>"
      ],
      "metadata": {
        "id": "n5M_dsvplMH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "skQsEViME-7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seed\n",
        "np.random.seed(10)\n",
        "\n",
        "# Generate 100 random numbers in the range 0 to 10\n",
        "random_numbers = np.random.randint(0, 11, size=100)\n",
        "random_numbers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4WRLv5TjRJX",
        "outputId": "407b26d7-6011-4e2f-bd08-6cd2b91869c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9,  4,  0,  1,  9,  0,  1, 10,  8,  9,  0, 10,  8,  6,  4,  3,  0,\n",
              "        4,  6,  8, 10,  1,  8,  4,  1,  3,  6,  5,  3,  9,  6,  9,  1,  9,\n",
              "        4,  2,  6,  7,  8, 10,  8,  9,  2,  0,  6,  7,  8,  1,  7,  1,  4,\n",
              "       10,  0,  8,  5,  4,  7,  8,  8,  2,  6,  2,  8,  8,  6,  6,  5, 10,\n",
              "        6,  0,  0,  6,  9,  1,  8, 10,  9,  1,  2,  8,  9,  9,  5,  0,  2,\n",
              "        7,  3,  0,  4,  2,  0,  3,  3,  1,  2,  5,  9,  0, 10,  1])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SparkContext(\"local\", \"RDD Task-1\")\n",
        "rdd = sc.parallelize(random_numbers)"
      ],
      "metadata": {
        "id": "VIwFg4uxjRG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frequency = rdd.map(lambda x: (x, 1)).reduceByKey(lambda a, b: a + b).sortByKey()\n",
        "for num, freq in frequency.collect():\n",
        "    print(f\"Number: {num}, Frequency: {freq}\")\n",
        "sc.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvHIFzQCjREr",
        "outputId": "815dbc16-0308-40cb-a2f8-8da2b7bd24bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number: 0, Frequency: 12\n",
            "Number: 1, Frequency: 11\n",
            "Number: 2, Frequency: 8\n",
            "Number: 3, Frequency: 6\n",
            "Number: 4, Frequency: 8\n",
            "Number: 5, Frequency: 5\n",
            "Number: 6, Frequency: 11\n",
            "Number: 7, Frequency: 5\n",
            "Number: 8, Frequency: 14\n",
            "Number: 9, Frequency: 12\n",
            "Number: 10, Frequency: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=\"6\">RDD Task-2</font>"
      ],
      "metadata": {
        "id": "Cf-ny_oEnosL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"RDD Task-2\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "H8Gtvzr2jRCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RDD\n",
        "text_rdd = sc.textFile(\"/content/drive/MyDrive/text8\")\n",
        "\n",
        "\n",
        "words_rdd = text_rdd.flatMap(lambda line: line.split())\n",
        "\n",
        "# frequency of each word\n",
        "word_frequencies = words_rdd.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "words_with_a_frequencies = word_frequencies.filter(lambda pair: 'a' in pair[0])\n",
        "\n",
        "# print the result\n",
        "results = words_with_a_frequencies.collect()"
      ],
      "metadata": {
        "id": "GL95hqU5jQ__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index,(word, frequency) in enumerate(results):\n",
        "    print(f\"Word: {word:20}Frequency: {frequency}\")\n",
        "    if index==50:\n",
        "      break\n",
        "sc.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6HVLnvwjQ94",
        "outputId": "d3f769ae-469e-422b-8a4d-99d76d65909d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: autonomous          Frequency: 404\n",
            "Word: william             Frequency: 3437\n",
            "Word: mikhail             Frequency: 215\n",
            "Word: travail             Frequency: 6\n",
            "Word: culminated          Frequency: 131\n",
            "Word: theoretical         Frequency: 614\n",
            "Word: adam                Frequency: 760\n",
            "Word: cease               Frequency: 241\n",
            "Word: classified          Frequency: 668\n",
            "Word: integration         Frequency: 498\n",
            "Word: pirate              Frequency: 168\n",
            "Word: statehood           Frequency: 88\n",
            "Word: boundary            Frequency: 587\n",
            "Word: didactic            Frequency: 29\n",
            "Word: graeme              Frequency: 29\n",
            "Word: generations         Frequency: 407\n",
            "Word: advertising         Frequency: 528\n",
            "Word: weak                Frequency: 663\n",
            "Word: warm                Frequency: 464\n",
            "Word: walk                Frequency: 549\n",
            "Word: timgad              Frequency: 1\n",
            "Word: fabric              Frequency: 153\n",
            "Word: hatchet             Frequency: 10\n",
            "Word: rays                Frequency: 304\n",
            "Word: diamond             Frequency: 590\n",
            "Word: ambitious           Frequency: 204\n",
            "Word: investigates        Frequency: 39\n",
            "Word: situated            Frequency: 458\n",
            "Word: ancestral           Frequency: 136\n",
            "Word: unearthed           Frequency: 43\n",
            "Word: magnus              Frequency: 136\n",
            "Word: rtca                Frequency: 1\n",
            "Word: dreamtime           Frequency: 6\n",
            "Word: acronyms            Frequency: 49\n",
            "Word: madagascar          Frequency: 201\n",
            "Word: thread              Frequency: 146\n",
            "Word: pyanepsia           Frequency: 1\n",
            "Word: realencyclop        Frequency: 2\n",
            "Word: khasian             Frequency: 1\n",
            "Word: pakanic             Frequency: 2\n",
            "Word: subclassification   Frequency: 4\n",
            "Word: generalized         Frequency: 200\n",
            "Word: totalitarianism     Frequency: 53\n",
            "Word: shishaldin          Frequency: 1\n",
            "Word: waits               Frequency: 37\n",
            "Word: gradual             Frequency: 189\n",
            "Word: moonwalkers         Frequency: 1\n",
            "Word: americana           Frequency: 42\n",
            "Word: pastizal            Frequency: 1\n",
            "Word: diurnal             Frequency: 23\n",
            "Word: whales              Frequency: 196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=\"6\">DataFrame Task:</font>"
      ],
      "metadata": {
        "id": "C0PN57Autnur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SparkSession.builder \\\n",
        "    .appName(\"DataFrame Task\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "iris_df = sc.read.json(\"/content/iris.json\")\n",
        "\n",
        "# Calculate Pearson Correlation between petalLength and petalWidth\n",
        "correlation = iris_df.stat.corr(\"petalLength\", \"petalWidth\")\n",
        "\n",
        "print(\"Pearson Correlation between petalLength and petalWidth:\", round(correlation,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQSFRJppjQ7Z",
        "outputId": "c0c66829-cafa-49d3-8958-5af2bef9a105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearson Correlation between petalLength and petalWidth: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show columns sepalLength, sepalWidth, and species for rows where petalLength >= 1.4\n",
        "filtered_df = iris_df.filter(iris_df[\"petalLength\"] >= 1.4).select(\"sepalLength\", \"sepalWidth\", \"species\")\n",
        "filtered_df.show()\n",
        "\n",
        "sc.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPKzo8gLjQ3K",
        "outputId": "65df4ffd-f99a-4b5f-e667-047396957da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+-------+\n",
            "|sepalLength|sepalWidth|species|\n",
            "+-----------+----------+-------+\n",
            "|        5.1|       3.5| setosa|\n",
            "|        4.9|       3.0| setosa|\n",
            "|        4.6|       3.1| setosa|\n",
            "|        5.0|       3.6| setosa|\n",
            "|        5.4|       3.9| setosa|\n",
            "|        4.6|       3.4| setosa|\n",
            "|        5.0|       3.4| setosa|\n",
            "|        4.4|       2.9| setosa|\n",
            "|        4.9|       3.1| setosa|\n",
            "|        5.4|       3.7| setosa|\n",
            "|        4.8|       3.4| setosa|\n",
            "|        4.8|       3.0| setosa|\n",
            "|        5.7|       4.4| setosa|\n",
            "|        5.1|       3.5| setosa|\n",
            "|        5.7|       3.8| setosa|\n",
            "|        5.1|       3.8| setosa|\n",
            "|        5.4|       3.4| setosa|\n",
            "|        5.1|       3.7| setosa|\n",
            "|        5.1|       3.3| setosa|\n",
            "|        4.8|       3.4| setosa|\n",
            "+-----------+----------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pRayfNk6oL4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xyhwgGD7vJyD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}